# app/services/chroma_service.py
import uuid
from chromadb.config import Settings
import os
from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain_openai import ChatOpenAI
from chromadb import Client as ChromaClient
from langchain_openai import OpenAIEmbeddings

# ì–¸ì–´ ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

# OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embedding_model = OpenAIEmbeddings(model="text-embedding-ada-002")


# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
prompt_template = ChatPromptTemplate.from_messages(
    [
        SystemMessagePromptTemplate.from_template(
            """
            ë‹¹ì‹ ì€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.
            
            ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì§ˆì˜ì‘ë‹µ ì„ ë¡€ : {context}

            ìœ„ ì„ ë¡€ì— ê¸°ë°˜í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """
        ),
        HumanMessagePromptTemplate.from_template("{question}"),
    ]
)


def load_vectorstore(id: str):
    # Chroma ë²¡í„° ìŠ¤í† ì–´ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = ChromaClient()

    # IDì— í•´ë‹¹í•˜ëŠ” ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    vectorstore = client.get_collection(name=id, embedding_function=embedding_model)

    return vectorstore


def query_vectorstore(vectorstore, question: str):
    # ì§ˆë¬¸ì„ ë²¡í„°(ì„ë² ë”©)ë¡œ ë³€í™˜
    question_embedding = embedding_model.embed_documents([question])[
        0
    ]  # ë²¡í„° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

    print("ì„ë² ë”©ëœ ì§ˆë¬¸:", question_embedding)

    # ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ì§ˆë¬¸ì— ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰
    results = vectorstore.query(
        query_texts=[question], n_results=1  # ì§ì ‘ ê²€ìƒ‰í•  ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬
    )

    print("ê²€ìƒ‰ ê²°ê³¼:", results)

    # í•„ìš”í•œ í˜•íƒœë¡œ ê²°ê³¼ ì²˜ë¦¬
    # í•„ìš”í•œ í˜•íƒœë¡œ ê²°ê³¼ ì²˜ë¦¬
    if results and len(results["metadatas"]) > 0:
        most_similar_metadata = results["metadatas"][0][
            0
        ]  # ì²« ë²ˆì§¸ ê²°ê³¼ì˜ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        answer = most_similar_metadata.get("answer", "ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€:", answer)
        return answer
    else:
        return "ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


class LangchainEmbeddingFunction:
    def __init__(self, embedding_model):
        self.embedding_model = embedding_model

    def __call__(self, input):
        return self.embedding_model.embed_documents(input)


def load_or_create_vectorstore(id: str, client: ChromaClient):
    print("ğŸ”§ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì¤‘...")

    # IDë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³ , Chromaì˜ ì»¬ë ‰ì…˜ ì´ë¦„ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ë„ë¡ ì¡°ì •
    id_str = f"collection_{id}"  # ì˜ˆ: "1" -> "collection_001"

    # ìƒˆë¡œìš´ ë˜í¼ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±
    embedding_function = LangchainEmbeddingFunction(embedding_model)

    try:
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì»¬ë ‰ì…˜ì„ ë¡œë“œ
        print("ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...")
        vectorstore = client.get_collection(
            name=id_str,
            embedding_function=embedding_function,  # ë˜í•‘ëœ ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš©
        )
        print("ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        # ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ìœ¼ë©´ ìƒì„±
        print(f"ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ ìƒì„±: {e}")
        vectorstore = client.create_collection(
            name=id_str,
            embedding_function=embedding_function,  # ë˜í•‘ëœ ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš©
        )
        print("ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")

    return vectorstore


# app/services/chroma_service.py


def append_to_vectorstore(vectorstore, question: str, answer: str):
    # ë‹¨ì¼ ë¬¸ìì—´ì´ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    questions = [question]
    answers = [answer]

    # ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì„ë² ë”© ìƒì„± ë° ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
    for question, answer in zip(questions, answers):
        # OpenAI ì„ë² ë”© ìƒì„±
        question_embedding = embedding_model.embed_documents([question])[0]

        # ë²¡í„° ìŠ¤í† ì–´ì— ì§ˆë¬¸ ë° ë‹µë³€ ì¶”ê°€
        vectorstore.add(
            embeddings=[question_embedding],  # embeddingsë¡œ ì „ë‹¬
            metadatas=[{"question": question, "answer": answer}],  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì „ë‹¬
            ids=[str(uuid.uuid4())],  # ê³ ìœ  ID ìƒì„±
        )
        print("ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ ì™„ë£Œ")
